{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mattchrlw/forecasting-on-new-roads"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiR6SzB-dQZk",
        "outputId": "c3d04efb-0076-4c5a-f721-9d874e241f3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'forecasting-on-new-roads'...\n",
            "remote: Enumerating objects: 82, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 82 (delta 24), reused 23 (delta 23), pack-reused 56\u001b[K\n",
            "Receiving objects: 100% (82/82), 5.57 MiB | 24.81 MiB/s, done.\n",
            "Resolving deltas: 100% (42/42), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# copy datasets\n",
        "!git clone https://github.com/deepkashiwa20/DL-Traff-Graph\n",
        "!mv DL-Traff-Graph/METRLA . && mv DL-Traff-Graph/PEMSBAY . && mv DL-Traff-Graph/PEMSD7M ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhmgSDlhXa0g",
        "outputId": "43f6b7b0-eb1e-459a-88af-1ad7a62d42aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DL-Traff-Graph'...\n",
            "remote: Enumerating objects: 529, done.\u001b[K\n",
            "remote: Counting objects: 100% (202/202), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 529 (delta 172), reused 148 (delta 134), pack-reused 327\u001b[K\n",
            "Receiving objects: 100% (529/529), 48.77 MiB | 23.64 MiB/s, done.\n",
            "Resolving deltas: 100% (288/288), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd forecasting-on-new-roads && python pred_GWN_16_adpAdj.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfOU1wa5W-3c",
        "outputId": "e2ebdf1a-7b1c-4f33-bc80-c4a02964efbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sys.argv ['pred_GWN_16_adpAdj.py']\n",
            "P.DATANAME == METRLA\n",
            "data.shape (34272, 207)\n",
            "pred_METRLA_GraphWaveNet_2402282056_4198 data splits Wed Feb 28 20:56:09 2024\n",
            "spatialSplit_unseen all: trn/val/tst : 207 : 144 / 20 / 41\n",
            "[162 188  59  81 189  64 161 124 174 136  88 179 112  41  74  31 157 134\n",
            "  65 177 185 139 115 125 169 165 120  69  11  46 186  15 111 104  99 142\n",
            " 171 200 184 101  75   3 127  85  32 175  26  90  92 197  52 170 166 201\n",
            "   7 160  77  28  29 116  40  83 123 110 168   1 167 192  97 133 202 128\n",
            " 203  73 118  57  44 154 183  96 152 206  10  20 172  82  12  16 126 145\n",
            "  89  45 148 117 191 194 149  51 182  39 122  37   6  54  25  21  48   9\n",
            "  23  35 178  50  62 146 163  19 196  55 190  22  42 102 187  33  76 119\n",
            " 156 114  95  84 198 181  71   5  36  43 164 199 140  70 131 150 151   0]\n",
            "[121 106  96  43 125 204 122 192 114 169 173  98 117 182  23 143   4  56\n",
            "  44  55]\n",
            "[ 21 155 154 110  61 189  52  17  97 151  13 182 153  42  85  70  74 107\n",
            " 197 206  93 146 185 117  88 184 108  38 156 162  35 164   0  48  20   2\n",
            " 180  22 165 118 102]\n",
            "spatialSplit_allNod all: trn/val/tst : 207 : 144 / 165 / 207\n",
            "[162 188  59  81 189  64 161 124 174 136  88 179 112  41  74  31 157 134\n",
            "  65 177 185 139 115 125 169 165 120  69  11  46 186  15 111 104  99 142\n",
            " 171 200 184 101  75   3 127  85  32 175  26  90  92 197  52 170 166 201\n",
            "   7 160  77  28  29 116  40  83 123 110 168   1 167 192  97 133 202 128\n",
            " 203  73 118  57  44 154 183  96 152 206  10  20 172  82  12  16 126 145\n",
            "  89  45 148 117 191 194 149  51 182  39 122  37   6  54  25  21  48   9\n",
            "  23  35 178  50  62 146 163  19 196  55 190  22  42 102 187  33  76 119\n",
            " 156 114  95  84 198 181  71   5  36  43 164 199 140  70 131 150 151   0]\n",
            "[121 106  96  43 125 204 122 192 114 169 173  98 117 182  23 143   4  56\n",
            "  44  55  63 188 146 103 105  78 144 134  24 109 108 148 149  54  57  18\n",
            " 205  73  12 160   7  14 155  75 196 140  89  79 190 107  28  95 138  22\n",
            " 166  33 163 152   1 194 191 127  21  97 178  37 124  91 189 174  67 168\n",
            "   9 110 179  64 153   5 157 184 129 202  81  34  86  69 170 199  46  50\n",
            " 133  94  45 100 136 195 201  27  82  30  51   0  72  58  76 118  90   6\n",
            " 167  11 197 135 120   3  20  19 180  15  17  60 156  84 185  80 161 145\n",
            "  31 112  25  47  77   8  59  88 183  74 193 132  26 203  35 171  39 130\n",
            " 150  10  83 151 181 198  65  87 141  66 147  41 101 158 104 128 116 165\n",
            " 142 172  40]\n",
            "[ 21 155 154 110  61 189  52  17  97 151  13 182 153  42  85  70  74 107\n",
            " 197 206  93 146 185 117  88 184 108  38 156 162  35 164   0  48  20   2\n",
            " 180  22 165 118 102  31 103 121 186 105 100 202 125 130 136 119 167  68\n",
            "  71  72  24  66  54 122 183  16  80 115 177 138 149  67 204 145  95  75\n",
            "  40  12 134  34  64 187 139 178   8 148  60  78  45 141  46 173  59 116\n",
            "  57 106 175  25 190  15  73 159 133 143 101 198 142 161  53 157 114  33\n",
            "   3 131  39  36 188 112 126  55 172 169  65  69  30 127 140   9 123  79\n",
            " 158  11  76  83 166 171 152  19   4 201  81  29 124 168 174 195 147  94\n",
            "  27  96   5 181  44 109 193 129  86  56  28 191  32 192 160  84  37   6\n",
            "  58 132 179 128  98  10 196  51 144 205  26 104 113 199 120  63 135 194\n",
            "  90  14  49 203  62  50 137 111  89 176 200 150  41  91   1  92  87  43\n",
            "  18  47  77   7  99 170  23  82 163]\n",
            "train.shape torch.Size([23969, 2, 144, 12]) torch.Size([23969, 12, 144, 1])\n",
            "val_u.shape torch.Size([3425, 2, 20, 12]) torch.Size([3425, 12, 20, 1])\n",
            "val_a.shape torch.Size([3425, 2, 165, 12]) torch.Size([3425, 12, 165, 1])\n",
            "tst_u.shape torch.Size([6844, 2, 41, 12]) torch.Size([6844, 12, 41, 1])\n",
            "tst_a.shape torch.Size([6844, 2, 207, 12]) torch.Size([6844, 12, 207, 1])\n",
            "adj_train 2 torch.Size([144, 144]) torch.Size([144, 144])\n",
            "adj_val_u 2 torch.Size([20, 20]) torch.Size([20, 20])\n",
            "adj_val_a 2 torch.Size([165, 165]) torch.Size([165, 165])\n",
            "adj_tst_u 2 torch.Size([41, 41]) torch.Size([41, 41])\n",
            "adj_tst_a 2 torch.Size([207, 207]) torch.Size([207, 207])\n",
            "pretrn_iter.dataset.tensors[0].shape torch.Size([144, 23969])\n",
            "preval_iter.dataset.tensors[0].shape torch.Size([20, 27394])\n",
            "TIMESTEP_IN 12\n",
            "TIMESTEP_OUT 12\n",
            "CHANNEL 2\n",
            "BATCHSIZE 64\n",
            "LEARN 0.001\n",
            "PRETRN_EPOCH 100\n",
            "EPOCH 100\n",
            "TRAINRATIO 0.8\n",
            "TRAINVALSPLIT 0.125\n",
            "ADJTYPE doubletransition\n",
            "MODELNAME GraphWaveNet\n",
            "IS_PRETRN True\n",
            "R_TRN 0.7\n",
            "IS_EPOCH_1 False\n",
            "seed 100\n",
            "TEMPERATURE 1.0\n",
            "DATANAME METRLA\n",
            "seed_SS 100\n",
            "IS_DESEASONED True\n",
            "weight_decay 0.0\n",
            "adp_adj False\n",
            "is_SGA True\n",
            "KEYWORD pred_METRLA_GraphWaveNet_2402282056_4198\n",
            "PATH ../save/pred_METRLA_GraphWaveNet_2402282056_4198\n",
            "FLOWPATH ../METRLA/metr-la.h5\n",
            "n_dct_coeff 3918\n",
            "ADJPATH ../METRLA/adj_mx.pkl\n",
            "N_NODE 207\n",
            "trainval_size 27394\n",
            "train_size 23969\n",
            "pred_METRLA_GraphWaveNet_2402282056_4198 pretraining started Wed Feb 28 20:56:14 2024\n",
            "pretrainModel Started ... Wed Feb 28 20:56:14 2024\n",
            "epoch 0 time used: 3  seconds  train loss: 4.149715900421143 validation loss: 3.5905354022979736\n",
            "epoch 1 time used: 0  seconds  train loss: 4.046429475148519 validation loss: 3.4715096950531006\n",
            "epoch 2 time used: 0  seconds  train loss: 3.9661769337124295 validation loss: 3.2439403533935547\n",
            "epoch 3 time used: 0  seconds  train loss: 3.9184737470414905 validation loss: 3.1087875366210938\n",
            "epoch 4 time used: 0  seconds  train loss: 3.8966197437710233 validation loss: 3.015270948410034\n",
            "epoch 5 time used: 0  seconds  train loss: 3.8795416090223522 validation loss: 2.9433810710906982\n",
            "epoch 6 time used: 0  seconds  train loss: 3.8583991792466907 validation loss: 2.9270169734954834\n",
            "epoch 7 time used: 0  seconds  train loss: 3.8460831907060413 validation loss: 2.923924207687378\n",
            "epoch 8 time used: 0  seconds  train loss: 3.8324411975012884 validation loss: 2.9121618270874023\n",
            "epoch 9 time used: 0  seconds  train loss: 3.827457163068983 validation loss: 2.9155433177948\n",
            "epoch 10 time used: 0  seconds  train loss: 3.82302369011773 validation loss: 2.8979344367980957\n",
            "epoch 11 time used: 0  seconds  train loss: 3.815346082051595 validation loss: 2.9088692665100098\n",
            "epoch 12 time used: 0  seconds  train loss: 3.81203556060791 validation loss: 2.8924388885498047\n",
            "epoch 13 time used: 0  seconds  train loss: 3.8059720198313394 validation loss: 2.9153225421905518\n",
            "epoch 14 time used: 0  seconds  train loss: 3.801740143034193 validation loss: 2.918450117111206\n",
            "epoch 15 time used: 0  seconds  train loss: 3.7957708835601807 validation loss: 2.8942291736602783\n",
            "epoch 16 time used: 0  seconds  train loss: 3.797137313418918 validation loss: 2.9125688076019287\n",
            "epoch 17 time used: 0  seconds  train loss: 3.7900028228759766 validation loss: 2.8760974407196045\n",
            "epoch 18 time used: 0  seconds  train loss: 3.789524210823907 validation loss: 2.882089853286743\n",
            "epoch 19 time used: 0  seconds  train loss: 3.7848659091525607 validation loss: 2.9013631343841553\n",
            "epoch 20 time used: 0  seconds  train loss: 3.782669358783298 validation loss: 2.9083023071289062\n",
            "epoch 21 time used: 0  seconds  train loss: 3.7830444971720376 validation loss: 2.8987672328948975\n",
            "epoch 22 time used: 0  seconds  train loss: 3.7804515626695423 validation loss: 2.9192540645599365\n",
            "epoch 23 time used: 0  seconds  train loss: 3.7773895263671875 validation loss: 2.8686954975128174\n",
            "epoch 24 time used: 0  seconds  train loss: 3.773619227939182 validation loss: 2.8914730548858643\n",
            "epoch 25 time used: 0  seconds  train loss: 3.772823068830702 validation loss: 2.9023237228393555\n",
            "epoch 26 time used: 0  seconds  train loss: 3.7742428514692516 validation loss: 2.908360719680786\n",
            "epoch 27 time used: 0  seconds  train loss: 3.7720021141899958 validation loss: 2.8856992721557617\n",
            "epoch 28 time used: 0  seconds  train loss: 3.7708988189697266 validation loss: 2.8712034225463867\n",
            "epoch 29 time used: 0  seconds  train loss: 3.7725272708468967 validation loss: 2.881800889968872\n",
            "epoch 30 time used: 0  seconds  train loss: 3.7653265264299183 validation loss: 2.8909788131713867\n",
            "epoch 31 time used: 0  seconds  train loss: 3.7656321790483265 validation loss: 2.873079299926758\n",
            "epoch 32 time used: 0  seconds  train loss: 3.76584349738227 validation loss: 2.864283561706543\n",
            "epoch 33 time used: 0  seconds  train loss: 3.763692617416382 validation loss: 2.8585355281829834\n",
            "epoch 34 time used: 0  seconds  train loss: 3.762106868955824 validation loss: 2.867119073867798\n",
            "epoch 35 time used: 0  seconds  train loss: 3.7595856719546847 validation loss: 2.881866455078125\n",
            "epoch 36 time used: 0  seconds  train loss: 3.7597579956054688 validation loss: 2.8731257915496826\n",
            "epoch 37 time used: 0  seconds  train loss: 3.759673489464654 validation loss: 2.877871513366699\n",
            "epoch 38 time used: 0  seconds  train loss: 3.757106754514906 validation loss: 2.8531594276428223\n",
            "epoch 39 time used: 0  seconds  train loss: 3.75571706559923 validation loss: 2.8595964908599854\n",
            "epoch 40 time used: 0  seconds  train loss: 3.756197690963745 validation loss: 2.8457839488983154\n",
            "epoch 41 time used: 0  seconds  train loss: 3.758023500442505 validation loss: 2.8439598083496094\n",
            "epoch 42 time used: 0  seconds  train loss: 3.7518212265438504 validation loss: 2.8449831008911133\n",
            "epoch 43 time used: 0  seconds  train loss: 3.7527729670206704 validation loss: 2.852978467941284\n",
            "epoch 44 time used: 0  seconds  train loss: 3.753092739317152 validation loss: 2.8545899391174316\n",
            "epoch 45 time used: 0  seconds  train loss: 3.750009854634603 validation loss: 2.8460967540740967\n",
            "epoch 46 time used: 0  seconds  train loss: 3.7494445376925998 validation loss: 2.853041172027588\n",
            "epoch 47 time used: 0  seconds  train loss: 3.75040684805976 validation loss: 2.835606098175049\n",
            "epoch 48 time used: 0  seconds  train loss: 3.748019642300076 validation loss: 2.8248562812805176\n",
            "epoch 49 time used: 0  seconds  train loss: 3.7488636440700955 validation loss: 2.8403217792510986\n",
            "epoch 50 time used: 0  seconds  train loss: 3.7469362682766385 validation loss: 2.8369052410125732\n",
            "epoch 51 time used: 0  seconds  train loss: 3.747037304772271 validation loss: 2.8321826457977295\n",
            "epoch 52 time used: 0  seconds  train loss: 3.74928445286221 validation loss: 2.8530280590057373\n",
            "epoch 53 time used: 0  seconds  train loss: 3.7449025313059487 validation loss: 2.834453582763672\n",
            "epoch 54 time used: 0  seconds  train loss: 3.749403264787462 validation loss: 2.8465981483459473\n",
            "epoch 55 time used: 0  seconds  train loss: 3.743360254499647 validation loss: 2.839514970779419\n",
            "epoch 56 time used: 0  seconds  train loss: 3.7433611022101507 validation loss: 2.8364930152893066\n",
            "epoch 57 time used: 0  seconds  train loss: 3.744398752848307 validation loss: 2.8577792644500732\n",
            "epoch 58 time used: 0  seconds  train loss: 3.7432546615600586 validation loss: 2.8544554710388184\n",
            "epoch 59 time used: 0  seconds  train loss: 3.742734909057617 validation loss: 2.8526315689086914\n",
            "epoch 60 time used: 0  seconds  train loss: 3.743452893363105 validation loss: 2.8415706157684326\n",
            "epoch 61 time used: 0  seconds  train loss: 3.7407041125827365 validation loss: 2.835777997970581\n",
            "epoch 62 time used: 0  seconds  train loss: 3.7406142817603216 validation loss: 2.8335022926330566\n",
            "epoch 63 time used: 0  seconds  train loss: 3.7396842108832464 validation loss: 2.840736150741577\n",
            "epoch 64 time used: 0  seconds  train loss: 3.7425046232011585 validation loss: 2.8243706226348877\n",
            "epoch 65 time used: 0  seconds  train loss: 3.741328345404731 validation loss: 2.84716796875\n",
            "epoch 66 time used: 0  seconds  train loss: 3.738942649629381 validation loss: 2.843248128890991\n",
            "epoch 67 time used: 0  seconds  train loss: 3.7392111354404025 validation loss: 2.857307195663452\n",
            "epoch 68 time used: 0  seconds  train loss: 3.741012520260281 validation loss: 2.8416497707366943\n",
            "epoch 69 time used: 0  seconds  train loss: 3.7387285232543945 validation loss: 2.838221311569214\n",
            "epoch 70 time used: 0  seconds  train loss: 3.7391279538472495 validation loss: 2.8344876766204834\n",
            "epoch 71 time used: 0  seconds  train loss: 3.7427416377597384 validation loss: 2.8219282627105713\n",
            "epoch 72 time used: 0  seconds  train loss: 3.738476276397705 validation loss: 2.8194124698638916\n",
            "epoch 73 time used: 0  seconds  train loss: 3.7385561731126575 validation loss: 2.8407719135284424\n",
            "epoch 74 time used: 0  seconds  train loss: 3.738554530673557 validation loss: 2.849717855453491\n",
            "epoch 75 time used: 0  seconds  train loss: 3.7374212476942272 validation loss: 2.844804525375366\n",
            "epoch 76 time used: 0  seconds  train loss: 3.7384641435411243 validation loss: 2.843374490737915\n",
            "epoch 77 time used: 0  seconds  train loss: 3.738530741797553 validation loss: 2.8504607677459717\n",
            "epoch 78 time used: 0  seconds  train loss: 3.735383881462945 validation loss: 2.8415095806121826\n",
            "epoch 79 time used: 0  seconds  train loss: 3.735653903749254 validation loss: 2.839437246322632\n",
            "epoch 80 time used: 0  seconds  train loss: 3.7397951549953885 validation loss: 2.8332459926605225\n",
            "epoch 81 time used: 0  seconds  train loss: 3.736041307449341 validation loss: 2.839006185531616\n",
            "epoch 82 time used: 0  seconds  train loss: 3.7351844840579562 validation loss: 2.846247434616089\n",
            "epoch 83 time used: 0  seconds  train loss: 3.7366623878479004 validation loss: 2.8552358150482178\n",
            "epoch 84 time used: 0  seconds  train loss: 3.7362978723314075 validation loss: 2.8594701290130615\n",
            "epoch 85 time used: 0  seconds  train loss: 3.736415253745185 validation loss: 2.83689022064209\n",
            "epoch 86 time used: 0  seconds  train loss: 3.7382339106665716 validation loss: 2.847879409790039\n",
            "epoch 87 time used: 0  seconds  train loss: 3.7357963191138372 validation loss: 2.8702292442321777\n",
            "epoch 88 time used: 0  seconds  train loss: 3.7378682030571833 validation loss: 2.875495672225952\n",
            "epoch 89 time used: 0  seconds  train loss: 3.734520117441813 validation loss: 2.856746196746826\n",
            "epoch 90 time used: 0  seconds  train loss: 3.735349072350396 validation loss: 2.854248285293579\n",
            "epoch 91 time used: 0  seconds  train loss: 3.7347470389472113 validation loss: 2.8557119369506836\n",
            "epoch 92 time used: 0  seconds  train loss: 3.7343862851460776 validation loss: 2.86879825592041\n",
            "epoch 93 time used: 0  seconds  train loss: 3.732689062754313 validation loss: 2.864863872528076\n",
            "epoch 94 time used: 0  seconds  train loss: 3.734859493043688 validation loss: 2.8543505668640137\n",
            "epoch 95 time used: 0  seconds  train loss: 3.7325333489312067 validation loss: 2.8354389667510986\n",
            "epoch 96 time used: 0  seconds  train loss: 3.7332944869995117 validation loss: 2.8655924797058105\n",
            "epoch 97 time used: 0  seconds  train loss: 3.732947826385498 validation loss: 2.842211961746216\n",
            "epoch 98 time used: 0  seconds  train loss: 3.7339732382032604 validation loss: 2.83085036277771\n",
            "epoch 99 time used: 0  seconds  train loss: 3.7340648439195423 validation loss: 2.845205783843994\n",
            "PRETIME DURATION: 2024-02-28 20:56:41.480877 - 2024-02-28 20:56:15.358866 = 0:00:26.122011\n",
            "pretrainModel Ended ... Wed Feb 28 20:56:41 2024\n",
            "pred_METRLA_GraphWaveNet_2402282056_4198 training started Wed Feb 28 20:56:41 2024\n",
            "trainModel Started ... Wed Feb 28 20:56:41 2024\n",
            "TIMESTEP_IN, TIMESTEP_OUT 12 12\n",
            "Model Training Started ... 2024-02-28 20:56:41.502050\n",
            "train_embed torch.Size([32, 144]) tensor(0.0100, device='cuda:0') tensor(1.0133, device='cuda:0')\n",
            "val_u_embed torch.Size([32, 20]) tensor(0.0256, device='cuda:0') tensor(0.9970, device='cuda:0')\n",
            "val_a_embed torch.Size([32, 165]) tensor(-0.0009, device='cuda:0') tensor(0.9968, device='cuda:0')\n",
            "epoch 0 time used: 25  seconds  train loss: 0.24688836246339724 validation unseen nodes loss: 0.2320044845168608 validation all nodes loss: 0.2308488582085519\n",
            "epoch 1 time used: 24  seconds  train loss: 0.21917609626049542 validation unseen nodes loss: 0.22834884391213855 validation all nodes loss: 0.22674441243175172\n",
            "epoch 2 time used: 31  seconds  train loss: 0.21505412653525613 validation unseen nodes loss: 0.23539667165627445 validation all nodes loss: 0.22894641771368737\n",
            "epoch 3 time used: 24  seconds  train loss: 0.21190661613193879 validation unseen nodes loss: 0.23424215048334024 validation all nodes loss: 0.2230996802645008\n",
            "epoch 4 time used: 24  seconds  train loss: 0.2093426336660329 validation unseen nodes loss: 0.23242994741801798 validation all nodes loss: 0.21860405655672951\n",
            "epoch 5 time used: 25  seconds  train loss: 0.2068004355190782 validation unseen nodes loss: 0.23215832213850787 validation all nodes loss: 0.21749287085376517\n",
            "epoch 6 time used: 24  seconds  train loss: 0.20428274063606167 validation unseen nodes loss: 0.23782568841084947 validation all nodes loss: 0.22104167629767507\n",
            "epoch 7 time used: 24  seconds  train loss: 0.20319130714468148 validation unseen nodes loss: 0.239449375641607 validation all nodes loss: 0.22011814730445833\n",
            "epoch 8 time used: 24  seconds  train loss: 0.2007780605227326 validation unseen nodes loss: 0.23931979418671046 validation all nodes loss: 0.2266627414165622\n",
            "epoch 9 time used: 24  seconds  train loss: 0.2005995110804429 validation unseen nodes loss: 0.2380811230153063 validation all nodes loss: 0.21895591449128451\n",
            "epoch 10 time used: 24  seconds  train loss: 0.19838417062107774 validation unseen nodes loss: 0.23990704649121222 validation all nodes loss: 0.22064711116526248\n",
            "epoch 11 time used: 24  seconds  train loss: 0.1978379879665144 validation unseen nodes loss: 0.2500746488310125 validation all nodes loss: 0.2230703095188976\n",
            "epoch 12 time used: 24  seconds  train loss: 0.1956482878523449 validation unseen nodes loss: 0.24300946228260542 validation all nodes loss: 0.2243093625689945\n",
            "epoch 13 time used: 24  seconds  train loss: 0.19491721783575475 validation unseen nodes loss: 0.24139441178662935 validation all nodes loss: 0.2202488196331219\n",
            "epoch 14 time used: 24  seconds  train loss: 0.19449182818522714 validation unseen nodes loss: 0.244409601570916 validation all nodes loss: 0.2194372809977427\n",
            "epoch 15 time used: 24  seconds  train loss: 0.19277790576844975 validation unseen nodes loss: 0.24849716202185973 validation all nodes loss: 0.2212264948778779\n",
            "epoch 16 time used: 24  seconds  train loss: 0.19234010123745005 validation unseen nodes loss: 0.260044558639944 validation all nodes loss: 0.2241044041275108\n",
            "epoch 17 time used: 24  seconds  train loss: 0.1923783901699484 validation unseen nodes loss: 0.25925587377844067 validation all nodes loss: 0.21877385090737447\n",
            "epoch 18 time used: 24  seconds  train loss: 0.19087967803388817 validation unseen nodes loss: 0.2765997069595504 validation all nodes loss: 0.21952251340786036\n",
            "epoch 19 time used: 24  seconds  train loss: 0.19043556459096064 validation unseen nodes loss: 0.2570416898666507 validation all nodes loss: 0.22158121811212414\n",
            "epoch 20 time used: 24  seconds  train loss: 0.1899021570067008 validation unseen nodes loss: 0.249452851201496 validation all nodes loss: 0.21785590804406327\n",
            "epoch 21 time used: 24  seconds  train loss: 0.18965273130991425 validation unseen nodes loss: 0.25912373600650007 validation all nodes loss: 0.22031804326676974\n",
            "epoch 22 time used: 24  seconds  train loss: 0.18890178379892553 validation unseen nodes loss: 0.27165114325328465 validation all nodes loss: 0.22148134660546798\n",
            "epoch 23 time used: 24  seconds  train loss: 0.18898636499062574 validation unseen nodes loss: 0.25781304637446023 validation all nodes loss: 0.22303421814511293\n",
            "epoch 24 time used: 24  seconds  train loss: 0.18807724340982365 validation unseen nodes loss: 0.2659015542181739 validation all nodes loss: 0.2214343098436829\n",
            "epoch 25 time used: 24  seconds  train loss: 0.1869246961078853 validation unseen nodes loss: 0.2653752067924416 validation all nodes loss: 0.2215205390696978\n",
            "epoch 26 time used: 24  seconds  train loss: 0.18700685999540578 validation unseen nodes loss: 0.2755074006188525 validation all nodes loss: 0.22110883276828014\n",
            "epoch 27 time used: 24  seconds  train loss: 0.18642690320218666 validation unseen nodes loss: 0.2684381927016878 validation all nodes loss: 0.22263618715923197\n",
            "epoch 28 time used: 24  seconds  train loss: 0.18544246013521418 validation unseen nodes loss: 0.27275098547448207 validation all nodes loss: 0.22188079686060438\n",
            "epoch 29 time used: 24  seconds  train loss: 0.18531193256109607 validation unseen nodes loss: 0.2775585823337527 validation all nodes loss: 0.2193317390358361\n",
            "epoch 30 time used: 24  seconds  train loss: 0.18493453930583006 validation unseen nodes loss: 0.26975986215319947 validation all nodes loss: 0.22486393310727865\n",
            "epoch 31 time used: 24  seconds  train loss: 0.18409126008390966 validation unseen nodes loss: 0.2552294136224872 validation all nodes loss: 0.22126173513214084\n",
            "epoch 32 time used: 24  seconds  train loss: 0.184558225325089 validation unseen nodes loss: 0.25058372755120273 validation all nodes loss: 0.2199615805993115\n",
            "epoch 33 time used: 24  seconds  train loss: 0.18416936597349529 validation unseen nodes loss: 0.2539542518610502 validation all nodes loss: 0.22385058261182186\n",
            "epoch 34 time used: 24  seconds  train loss: 0.1828929297372682 validation unseen nodes loss: 0.2638118294860325 validation all nodes loss: 0.22425453460129507\n",
            "epoch 35 time used: 24  seconds  train loss: 0.1828060017031351 validation unseen nodes loss: 0.28001160366691813 validation all nodes loss: 0.222364823844311\n",
            "epoch 36 time used: 24  seconds  train loss: 0.18185903087946545 validation unseen nodes loss: 0.2696537235052916 validation all nodes loss: 0.22611711391567313\n",
            "epoch 37 time used: 24  seconds  train loss: 0.18168277760670837 validation unseen nodes loss: 0.2729224514134609 validation all nodes loss: 0.2233870059817377\n",
            "epoch 38 time used: 24  seconds  train loss: 0.18122904060358816 validation unseen nodes loss: 0.2827560535225555 validation all nodes loss: 0.22142801522338476\n",
            "epoch 39 time used: 24  seconds  train loss: 0.1807102085084918 validation unseen nodes loss: 0.27863467592827595 validation all nodes loss: 0.22385104014055573\n",
            "epoch 40 time used: 24  seconds  train loss: 0.18079215024319234 validation unseen nodes loss: 0.2637425368110629 validation all nodes loss: 0.2224029667360069\n",
            "epoch 41 time used: 24  seconds  train loss: 0.17983461342880358 validation unseen nodes loss: 0.2723141384298784 validation all nodes loss: 0.22472421402043669\n",
            "epoch 42 time used: 24  seconds  train loss: 0.17990171072544633 validation unseen nodes loss: 0.2882282363846354 validation all nodes loss: 0.22611134407294056\n",
            "epoch 43 time used: 24  seconds  train loss: 0.1789927420181617 validation unseen nodes loss: 0.26643498727004894 validation all nodes loss: 0.22339173280844724\n",
            "epoch 44 time used: 24  seconds  train loss: 0.17906688938807216 validation unseen nodes loss: 0.2593046935674918 validation all nodes loss: 0.22405778901855442\n",
            "epoch 45 time used: 24  seconds  train loss: 0.17889708910205646 validation unseen nodes loss: 0.2614336288714931 validation all nodes loss: 0.2254989039245313\n",
            "epoch 46 time used: 24  seconds  train loss: 0.17801266711385066 validation unseen nodes loss: 0.2683961822647248 validation all nodes loss: 0.22542174897054687\n",
            "epoch 47 time used: 24  seconds  train loss: 0.17830393482303483 validation unseen nodes loss: 0.2677717830099329 validation all nodes loss: 0.22476181016351185\n",
            "epoch 48 time used: 24  seconds  train loss: 0.1776524358104767 validation unseen nodes loss: 0.28053877961896634 validation all nodes loss: 0.22502789982478985\n",
            "epoch 49 time used: 24  seconds  train loss: 0.17718408592883028 validation unseen nodes loss: 0.26821201798689626 validation all nodes loss: 0.22624715102415016\n",
            "epoch 50 time used: 24  seconds  train loss: 0.17693406051952115 validation unseen nodes loss: 0.26372830247356943 validation all nodes loss: 0.22497086019411575\n",
            "epoch 51 time used: 24  seconds  train loss: 0.17691085290312494 validation unseen nodes loss: 0.2755620053606312 validation all nodes loss: 0.2231409848214936\n",
            "epoch 52 time used: 24  seconds  train loss: 0.17652472834201852 validation unseen nodes loss: 0.26767552056016714 validation all nodes loss: 0.22408636342434987\n",
            "epoch 53 time used: 24  seconds  train loss: 0.1766640123119292 validation unseen nodes loss: 0.279110491428062 validation all nodes loss: 0.22649234128259393\n",
            "epoch 54 time used: 24  seconds  train loss: 0.175532385000046 validation unseen nodes loss: 0.27048564784283186 validation all nodes loss: 0.22482120728840793\n",
            "epoch 55 time used: 24  seconds  train loss: 0.17551951073559272 validation unseen nodes loss: 0.27575783738254633 validation all nodes loss: 0.2254378457965642\n",
            "epoch 56 time used: 24  seconds  train loss: 0.17519249159212807 validation unseen nodes loss: 0.32224418159818996 validation all nodes loss: 0.22379055585739385\n",
            "epoch 57 time used: 24  seconds  train loss: 0.17530180951524843 validation unseen nodes loss: 0.2901473732934381 validation all nodes loss: 0.22869428777346645\n",
            "epoch 58 time used: 24  seconds  train loss: 0.17509997930540758 validation unseen nodes loss: 0.28398869648031944 validation all nodes loss: 0.22818460782514002\n",
            "epoch 59 time used: 24  seconds  train loss: 0.17532391052475071 validation unseen nodes loss: 0.3054258466419512 validation all nodes loss: 0.2278699931785138\n",
            "epoch 60 time used: 24  seconds  train loss: 0.1755590138935845 validation unseen nodes loss: 0.28972203675412783 validation all nodes loss: 0.22628921818559186\n",
            "epoch 61 time used: 24  seconds  train loss: 0.17426081014751788 validation unseen nodes loss: 0.2705023018939652 validation all nodes loss: 0.225342790902096\n",
            "epoch 62 time used: 24  seconds  train loss: 0.17390636804691317 validation unseen nodes loss: 0.2782637372199636 validation all nodes loss: 0.22671930078607405\n",
            "epoch 63 time used: 24  seconds  train loss: 0.17365607760843196 validation unseen nodes loss: 0.31466917265070615 validation all nodes loss: 0.22639091869775396\n",
            "epoch 64 time used: 24  seconds  train loss: 0.17342887676136678 validation unseen nodes loss: 0.32120494491862556 validation all nodes loss: 0.22957647885284285\n",
            "epoch 65 time used: 24  seconds  train loss: 0.1736705903329272 validation unseen nodes loss: 0.28357906742687644 validation all nodes loss: 0.22926958942065273\n",
            "epoch 66 time used: 24  seconds  train loss: 0.17605956695202052 validation unseen nodes loss: 0.2933181550554986 validation all nodes loss: 0.2326856223901693\n",
            "epoch 67 time used: 24  seconds  train loss: 0.17292682123393588 validation unseen nodes loss: 0.2949532171235467 validation all nodes loss: 0.22722999713281644\n",
            "epoch 68 time used: 24  seconds  train loss: 0.17303704595510094 validation unseen nodes loss: 0.28645454571194895 validation all nodes loss: 0.2279925350986258\n",
            "epoch 69 time used: 24  seconds  train loss: 0.1723945107709044 validation unseen nodes loss: 0.28514324876513797 validation all nodes loss: 0.22838124587152997\n",
            "epoch 70 time used: 24  seconds  train loss: 0.17251033574868674 validation unseen nodes loss: 0.26095238633399465 validation all nodes loss: 0.22476589107600442\n",
            "epoch 71 time used: 24  seconds  train loss: 0.17253845857611047 validation unseen nodes loss: 0.323817407693306 validation all nodes loss: 0.22810458748880094\n",
            "epoch 72 time used: 24  seconds  train loss: 0.17215984058204065 validation unseen nodes loss: 0.287791019425775 validation all nodes loss: 0.23301712516885603\n",
            "epoch 73 time used: 24  seconds  train loss: 0.1718456823100753 validation unseen nodes loss: 0.2781905145714753 validation all nodes loss: 0.2303724522138164\n",
            "epoch 74 time used: 24  seconds  train loss: 0.17196992060258245 validation unseen nodes loss: 0.27110143226428624 validation all nodes loss: 0.2301810780189333\n",
            "epoch 75 time used: 24  seconds  train loss: 0.171356496169981 validation unseen nodes loss: 0.3167380090308015 validation all nodes loss: 0.2301038953553151\n",
            "epoch 76 time used: 24  seconds  train loss: 0.17132643969479547 validation unseen nodes loss: 0.27917548105664497 validation all nodes loss: 0.22844832279386312\n",
            "epoch 77 time used: 24  seconds  train loss: 0.1716211503138853 validation unseen nodes loss: 0.3175455039348045 validation all nodes loss: 0.23212222581362202\n",
            "epoch 78 time used: 24  seconds  train loss: 0.17131176412620316 validation unseen nodes loss: 0.3000318661310377 validation all nodes loss: 0.22970025436721578\n",
            "epoch 79 time used: 24  seconds  train loss: 0.17079471275126454 validation unseen nodes loss: 0.28790104349599266 validation all nodes loss: 0.23090727778681874\n",
            "epoch 80 time used: 24  seconds  train loss: 0.17086832507008073 validation unseen nodes loss: 0.3098716802492629 validation all nodes loss: 0.2311799882711285\n",
            "epoch 81 time used: 24  seconds  train loss: 0.1711744878292979 validation unseen nodes loss: 0.3420449249848832 validation all nodes loss: 0.2329529212469602\n",
            "epoch 82 time used: 24  seconds  train loss: 0.17042137886785666 validation unseen nodes loss: 0.301046684619284 validation all nodes loss: 0.2386718645626611\n",
            "epoch 83 time used: 24  seconds  train loss: 0.170470210767602 validation unseen nodes loss: 0.3290253706135019 validation all nodes loss: 0.23315832252049967\n",
            "epoch 84 time used: 24  seconds  train loss: 0.17032203488208866 validation unseen nodes loss: 0.28482950860566464 validation all nodes loss: 0.23020129635821293\n",
            "epoch 85 time used: 24  seconds  train loss: 0.17058507897259123 validation unseen nodes loss: 0.2979093633864048 validation all nodes loss: 0.23143510663161312\n",
            "epoch 86 time used: 24  seconds  train loss: 0.17042139833280542 validation unseen nodes loss: 0.29568006851377276 validation all nodes loss: 0.2308928436824005\n",
            "epoch 87 time used: 24  seconds  train loss: 0.16969676201518802 validation unseen nodes loss: 0.32835553820985947 validation all nodes loss: 0.23213502766877195\n",
            "epoch 88 time used: 24  seconds  train loss: 0.16954861243315544 validation unseen nodes loss: 0.28466961494327464 validation all nodes loss: 0.23522517126407066\n",
            "epoch 89 time used: 24  seconds  train loss: 0.16957817673608563 validation unseen nodes loss: 0.3163904136897874 validation all nodes loss: 0.23350838647706665\n",
            "epoch 90 time used: 24  seconds  train loss: 0.17001989023444689 validation unseen nodes loss: 0.3173689097992695 validation all nodes loss: 0.23101516942038153\n",
            "epoch 91 time used: 24  seconds  train loss: 0.16939591971094356 validation unseen nodes loss: 0.29705402839792905 validation all nodes loss: 0.2338161512621998\n",
            "epoch 92 time used: 24  seconds  train loss: 0.1692736918927532 validation unseen nodes loss: 0.3086693742936545 validation all nodes loss: 0.23408040078452033\n",
            "epoch 93 time used: 24  seconds  train loss: 0.16904285477131706 validation unseen nodes loss: 0.30505910470537895 validation all nodes loss: 0.23417679519113832\n",
            "epoch 94 time used: 24  seconds  train loss: 0.16894619690620424 validation unseen nodes loss: 0.3051992272678083 validation all nodes loss: 0.23141383132795348\n",
            "epoch 95 time used: 24  seconds  train loss: 0.16924158100506118 validation unseen nodes loss: 0.2913192836646616 validation all nodes loss: 0.23254812133138197\n",
            "epoch 96 time used: 24  seconds  train loss: 0.16867310735041322 validation unseen nodes loss: 0.3517675937962358 validation all nodes loss: 0.236197284294741\n",
            "epoch 97 time used: 24  seconds  train loss: 0.1688806654170396 validation unseen nodes loss: 0.30979310704843843 validation all nodes loss: 0.2323203198405078\n",
            "epoch 98 time used: 24  seconds  train loss: 0.16872117437714157 validation unseen nodes loss: 0.3215871670733403 validation all nodes loss: 0.23383783303038047\n",
            "epoch 99 time used: 24  seconds  train loss: 0.16866608455729298 validation unseen nodes loss: 0.349283667298129 validation all nodes loss: 0.23478547282462572\n",
            "MODEL TRAINING DURATION: 2024-02-28 21:37:40.162682 - 2024-02-28 20:56:41.502050 = 0:40:58.660632\n",
            "****************************************\n",
            "GraphWaveNet, train, MAE on train, 1.6776338743e-01, 0.1677633874\n",
            "min_val_u_loss 0.22834884391213855\n",
            "min_val_a_loss 0.21749287085376517\n",
            "trainModel Ended ... Wed Feb 28 21:37:48 2024\n",
            "pred_METRLA_GraphWaveNet_2402282056_4198 testing started Wed Feb 28 21:37:48 2024\n",
            "Model Testing test_u Started ... Wed Feb 28 21:37:48 2024\n",
            "TIMESTEP_IN, TIMESTEP_OUT 12 12\n",
            "Model Infer Start ... 2024-02-28 21:37:48.135135\n",
            "Model Infer End ... 2024-02-28 21:37:49.860126\n",
            "MODEL INFER DURATION: 2024-02-28 21:37:49.860126 - 2024-02-28 21:37:48.135135 = 0:00:01.724991\n",
            "YS.shape, YS_pred.shape, (6844, 12, 41, 1) (6844, 12, 41, 1)\n",
            "YS.shape, YS_pred.shape, (6844, 12, 41) (6844, 12, 41)\n",
            "****************************************\n",
            "GraphWaveNet, test_u, Torch MSE, 2.5127682304e-01, 0.2512768230\n",
            "all pred steps, GraphWaveNet, test_u, MSE, RMSE, MAE, MAPE, 111.1768341064, 10.5440425873, 4.5640664101, 13.1239548326\n",
            "1 step, GraphWaveNet, test_u, MSE, RMSE, MAE, MAPE, 31.6473102570, 5.6255941391, 2.5463466644, 6.0972183943\n",
            "2 step, GraphWaveNet, test_u, MSE, RMSE, MAE, MAPE, 48.9221153259, 6.9944348335, 3.0436387062, 7.7514857054\n",
            "3 step, GraphWaveNet, test_u, MSE, RMSE, MAE, MAPE, 63.1925849915, 7.9493765831, 3.4476513863, 9.2847652733\n",
            "4 step, GraphWaveNet, test_u, MSE, RMSE, MAE, MAPE, 79.8998413086, 8.9386711121, 3.8490390778, 10.6294170022\n",
            "5 step, GraphWaveNet, test_u, MSE, RMSE, MAE, MAPE, 93.9380798340, 9.6921663284, 4.2085971832, 11.8859186769\n",
            "6 step, GraphWaveNet, test_u, MSE, RMSE, MAE, MAPE, 109.3972930908, 10.4593162537, 4.5543437004, 13.0321130157\n",
            "7 step, GraphWaveNet, test_u, MSE, RMSE, MAE, MAPE, 122.7521057129, 11.0793552399, 4.8707108498, 14.1743853688\n",
            "8 step, GraphWaveNet, test_u, MSE, RMSE, MAE, MAPE, 135.6450042725, 11.6466732025, 5.1333584785, 14.9506926537\n",
            "9 step, GraphWaveNet, test_u, MSE, RMSE, MAE, MAPE, 146.4802246094, 12.1029014587, 5.4262719154, 16.0835608840\n",
            "10 step, GraphWaveNet, test_u, MSE, RMSE, MAE, MAPE, 157.6177368164, 12.5545902252, 5.6749911308, 17.1141833067\n",
            "11 step, GraphWaveNet, test_u, MSE, RMSE, MAE, MAPE, 167.2735443115, 12.9334278107, 5.8914031982, 17.8164035082\n",
            "12 step, GraphWaveNet, test_u, MSE, RMSE, MAE, MAPE, 177.3565063477, 13.3175258636, 6.1224241257, 18.6672866344\n",
            "Model Testing Ended ... Wed Feb 28 21:37:52 2024\n",
            "Model Testing test_a Started ... Wed Feb 28 21:37:52 2024\n",
            "TIMESTEP_IN, TIMESTEP_OUT 12 12\n",
            "Model Infer Start ... 2024-02-28 21:37:52.204877\n",
            "Model Infer End ... 2024-02-28 21:37:55.869088\n",
            "MODEL INFER DURATION: 2024-02-28 21:37:55.869088 - 2024-02-28 21:37:52.204877 = 0:00:03.664211\n",
            "YS.shape, YS_pred.shape, (6844, 12, 207, 1) (6844, 12, 207, 1)\n",
            "YS.shape, YS_pred.shape, (6844, 12, 207) (6844, 12, 207)\n",
            "****************************************\n",
            "GraphWaveNet, test_a, Torch MSE, 2.5466506767e-01, 0.2546650677\n",
            "all pred steps, GraphWaveNet, test_a, MSE, RMSE, MAE, MAPE, 106.3532638550, 10.3127717972, 4.5350742340, 12.0101094246\n",
            "1 step, GraphWaveNet, test_a, MSE, RMSE, MAE, MAPE, 32.7342147827, 5.7213821411, 2.7117764950, 6.3743546605\n",
            "2 step, GraphWaveNet, test_a, MSE, RMSE, MAE, MAPE, 48.3132514954, 6.9507732391, 3.1811833382, 7.6977550983\n",
            "3 step, GraphWaveNet, test_a, MSE, RMSE, MAE, MAPE, 61.5740890503, 7.8469157219, 3.5294809341, 8.8343665004\n",
            "4 step, GraphWaveNet, test_a, MSE, RMSE, MAE, MAPE, 76.9091110229, 8.7697839737, 3.8866803646, 9.9011197686\n",
            "5 step, GraphWaveNet, test_a, MSE, RMSE, MAE, MAPE, 91.3710174561, 9.5588188171, 4.2289376259, 11.0053278506\n",
            "6 step, GraphWaveNet, test_a, MSE, RMSE, MAE, MAPE, 104.7035217285, 10.2324743271, 4.5166363716, 11.8851125240\n",
            "7 step, GraphWaveNet, test_a, MSE, RMSE, MAE, MAPE, 116.6805725098, 10.8018779755, 4.8068361282, 12.8409579396\n",
            "8 step, GraphWaveNet, test_a, MSE, RMSE, MAE, MAPE, 128.9706268311, 11.3565235138, 5.0747818947, 13.7110143900\n",
            "9 step, GraphWaveNet, test_a, MSE, RMSE, MAE, MAPE, 138.6926269531, 11.7767829895, 5.2951846123, 14.4224107265\n",
            "10 step, GraphWaveNet, test_a, MSE, RMSE, MAE, MAPE, 149.1226196289, 12.2115774155, 5.5158562660, 15.1561915874\n",
            "11 step, GraphWaveNet, test_a, MSE, RMSE, MAE, MAPE, 158.7765045166, 12.6006546021, 5.7321982384, 15.8000886440\n",
            "12 step, GraphWaveNet, test_a, MSE, RMSE, MAE, MAPE, 168.3989715576, 12.9768629074, 5.9415497780, 16.4931610227\n",
            "Model Testing Ended ... Wed Feb 28 21:38:03 2024\n",
            "SCRIPT DURATION 0:41:54.406424\n"
          ]
        }
      ]
    }
  ]
}